{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "import os, urllib\n",
    "\n",
    "def save_net(model, prefix):\n",
    "    model.save_params(prefix+'-0001.params')\n",
    "    model.symbol.save(prefix+'-symbol.json')\n",
    "    \n",
    "def print_net_params(param):\n",
    "    for m in sorted(param):\n",
    "        print m, param[m].shape\n",
    "        \n",
    "def plot_network(symbol, name='network'):\n",
    "    graph = mx.viz.plot_network(symbol=symbol)\n",
    "    graph.format = 'png'\n",
    "    graph.render('network.gv', view=True)\n",
    "    \n",
    "def print_inferred_shape(net, name, nch=3, size=300, node_type='rgb'):\n",
    "    if node_type == 'rgb':\n",
    "        ar, ou, au = net.infer_shape(rgb=(1, nch, size, size))\n",
    "    if node_type == 'spectral':\n",
    "        ar, ou, au = net.infer_shape(rgb=(1, nch, size, size), tir=(1, 1, size, size))\n",
    "    print ou\n",
    "\n",
    "\n",
    "# Batch = namedtuple('Batch', ['data'])\n",
    "# import matplotlib.pyplot as plt \n",
    "# import numpy as np\n",
    "# %matplotlib inline \n",
    "\n",
    "# def download(url,prefix=''):\n",
    "#     filename = prefix+url.split(\"/\")[-1]\n",
    "#     if not os.path.exists(filename):\n",
    "#         urllib.urlretrieve(url, filename)\n",
    "        \n",
    "# def get_image(url, show=True):\n",
    "#     filename = url.split(\"/\")[-1]\n",
    "#     urllib.urlretrieve(url, filename)\n",
    "#     img = cv2.imread(filename)\n",
    "#     if img is None:\n",
    "#         print('failed to download ' + url)\n",
    "#     if show:\n",
    "#         plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#         plt.axis('off')\n",
    "#     return filename\n",
    "\n",
    "# url = 'http://writm.com/wp-content/uploads/2016/08/Cat-hd-wallpapers.jpg'\n",
    "# img = get_image(url)\n",
    "\n",
    "# size = 300\n",
    "# img= cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# img = cv2.resize(img, (size, size))\n",
    "# img = np.swapaxes(img, 0, 2)\n",
    "# img = np.swapaxes(img, 1, 2) \n",
    "# img = img[np.newaxis, :] \n",
    "# print img.shape\n",
    "# batch = img\n",
    "\n",
    "def multibox_layer(from_layers, num_classes, sizes=[.2, .95], ratios=[1], normalization=-1, num_channels=[], clip=True, interm_layer=0):\n",
    "    \"\"\"\n",
    "    the basic aggregation module for SSD detection. Takes in multiple layers,\n",
    "    generate multiple object detection targets by customized layers\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    from_layers : list of mx.symbol\n",
    "        generate multibox detection from layers\n",
    "    num_classes : int\n",
    "        number of classes excluding background, will automatically handle\n",
    "        background in this function\n",
    "    sizes : list or list of list\n",
    "        [min_size, max_size] for all layers or [[], [], []...] for specific layers\n",
    "    ratios : list or list of list\n",
    "        [ratio1, ratio2...] for all layers or [[], [], ...] for specific layers\n",
    "    normalizations : int or list of int\n",
    "        use normalizations value for all layers or [...] for specific layers,\n",
    "        -1 indicate no normalizations and scales\n",
    "    num_channels : list of int\n",
    "        number of input layer channels, used when normalization is enabled, the\n",
    "        length of list should equals to number of normalization layers\n",
    "    clip : bool\n",
    "        whether to clip out-of-image boxes\n",
    "    interm_layer : int\n",
    "        if > 0, will add a intermediate Convolution layer\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    list of outputs, as [loc_preds, cls_preds, anchor_boxes]\n",
    "    loc_preds : localization regression prediction\n",
    "    cls_preds : classification prediction\n",
    "    anchor_boxes : generated anchor boxes\n",
    "    \"\"\"\n",
    "    assert len(from_layers) > 0, \"from_layers must not be empty list\"\n",
    "    assert num_classes > 0,      \"num_classes {} must be larger than 0\".format(num_classes)\n",
    "\n",
    "    assert len(ratios) > 0, \"aspect ratios must not be empty list\"\n",
    "    if not isinstance(ratios[0], list):\n",
    "        # provided only one ratio list, broadcast to all from_layers\n",
    "        ratios = [ratios] * len(from_layers)\n",
    "    assert len(ratios) == len(from_layers), \\\n",
    "        \"ratios and from_layers must have same length\"\n",
    "\n",
    "    assert len(sizes) > 0, \"sizes must not be empty list\"\n",
    "    if len(sizes) == 2 and not isinstance(sizes[0], list):\n",
    "        # provided size range, we need to compute the sizes for each layer\n",
    "         assert sizes[0] > 0 and sizes[0] < 1\n",
    "         assert sizes[1] > 0 and sizes[1] < 1 and sizes[1] > sizes[0]\n",
    "         tmp = np.linspace(sizes[0], sizes[1], num=(len(from_layers)-1))\n",
    "         min_sizes = [start_offset] + tmp.tolist()\n",
    "         max_sizes = tmp.tolist() + [tmp[-1]+start_offset]\n",
    "         sizes = zip(min_sizes, max_sizes)\n",
    "    assert len(sizes) == len(from_layers), \\\n",
    "        \"sizes and from_layers must have same length\"\n",
    "\n",
    "    if not isinstance(normalization, list):\n",
    "        normalization = [normalization] * len(from_layers)\n",
    "    assert len(normalization) == len(from_layers)\n",
    "\n",
    "    assert sum(x > 0 for x in normalization) == len(num_channels), \\\n",
    "        \"must provide number of channels for each normalized layer\"\n",
    "\n",
    "    loc_pred_layers = []\n",
    "    cls_pred_layers = []\n",
    "    anchor_layers = []\n",
    "    num_classes += 1 # always use background as label 0\n",
    "\n",
    "    for k, from_layer in enumerate(from_layers):\n",
    "        from_name = from_layer.name\n",
    "        # normalize\n",
    "        if normalization[k] > 0:\n",
    "            from_layer = mx.symbol.L2Normalization(data=from_layer, mode=\"channel\", name=\"{}_norm\".format(from_name))\n",
    "            scale = mx.symbol.Variable(name=\"{}_scale\".format(from_name),shape=(1, num_channels.pop(0), 1, 1))\n",
    "            from_layer = normalization[k] * mx.symbol.broadcast_mul(lhs=scale, rhs=from_layer)\n",
    "        if interm_layer > 0:\n",
    "            from_layer = mx.symbol.Convolution(data=from_layer, kernel=(3,3), stride=(1,1), pad=(1,1), num_filter=interm_layer, name=\"{}_inter_conv\".format(from_name))\n",
    "            from_layer = mx.symbol.Activation(data=from_layer, act_type=\"relu\", name=\"{}_inter_relu\".format(from_name))\n",
    "\n",
    "        # estimate number of anchors per location\n",
    "        # here I follow the original version in caffe\n",
    "        # TODO: better way to shape the anchors??\n",
    "        size = sizes[k]\n",
    "        assert len(size) > 0, \"must provide at least one size\"\n",
    "        size_str = \"(\" + \",\".join([str(x) for x in size]) + \")\"\n",
    "        ratio = ratios[k]\n",
    "        assert len(ratio) > 0, \"must provide at least one ratio\"\n",
    "        ratio_str = \"(\" + \",\".join([str(x) for x in ratio]) + \")\"\n",
    "        num_anchors = len(size) -1 + len(ratio)\n",
    "\n",
    "        # create location prediction layer\n",
    "        num_loc_pred = num_anchors * 4\n",
    "        loc_pred = mx.symbol.Convolution(data=from_layer, kernel=(3,3), stride=(1,1), pad=(1,1), num_filter=num_loc_pred, name=\"{}_loc_pred_conv\".format(from_name))\n",
    "        loc_pred = mx.symbol.transpose(loc_pred, axes=(0,2,3,1))\n",
    "        loc_pred = mx.symbol.Flatten(data=loc_pred)\n",
    "        loc_pred_layers.append(loc_pred)\n",
    "\n",
    "        # create class prediction layer\n",
    "        num_cls_pred = num_anchors * num_classes\n",
    "        cls_pred = mx.symbol.Convolution(data=from_layer, kernel=(3,3), stride=(1,1), pad=(1,1), num_filter=num_cls_pred, name=\"{}_cls_pred_conv\".format(from_name))\n",
    "        cls_pred = mx.symbol.transpose(cls_pred, axes=(0,2,3,1))\n",
    "        cls_pred = mx.symbol.Flatten(data=cls_pred)\n",
    "        cls_pred_layers.append(cls_pred)\n",
    "\n",
    "        # create anchor generation layer\n",
    "        anchors = mx.contrib.symbol.MultiBoxPrior(from_layer, sizes=size_str, ratios=ratio_str, clip=clip, name=\"{}_anchors\".format(from_name))\n",
    "        anchors = mx.symbol.Flatten(data=anchors)\n",
    "        anchor_layers.append(anchors)\n",
    "\n",
    "    loc_preds = mx.symbol.Concat(*loc_pred_layers, num_args=len(loc_pred_layers), dim=1, name=\"multibox_loc_pred\")\n",
    "    cls_preds = mx.symbol.Concat(*cls_pred_layers, num_args=len(cls_pred_layers), dim=1)\n",
    "    cls_preds = mx.symbol.Reshape(data=cls_preds, shape=(0, -1, num_classes))\n",
    "    cls_preds = mx.symbol.transpose(cls_preds, axes=(0, 2, 1), name=\"multibox_cls_pred\")\n",
    "    anchor_boxes = mx.symbol.Concat(*anchor_layers, num_args=len(anchor_layers), dim=1)\n",
    "    anchor_boxes = mx.symbol.Reshape(data=anchor_boxes, shape=(0, -1, 4), name=\"multibox_anchors\")\n",
    "    return [loc_preds, cls_preds, anchor_boxes]\n",
    "\n",
    "\n",
    "def bn_act_conv_layer(from_layer, name, num_filter, kernel=(1,1), pad=(0,0), stride=(1,1)):\n",
    "    bn = mx.symbol.BatchNorm(data=from_layer, name=\"bn{}\".format(name))\n",
    "    relu = mx.symbol.Activation(data=bn, act_type='relu')\n",
    "    conv = mx.symbol.Convolution(data=relu, kernel=kernel, pad=pad, stride=stride, num_filter=num_filter, name=\"conv{}\".format(name))\n",
    "    return conv, relu\n",
    "\n",
    "\n",
    "def residual_unit(data, num_filter, stride, dim_match, name, bn_mom=0.9, workspace=256):\n",
    "        bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn1')\n",
    "        act1 =  mx.symbol.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "        conv1 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3,3), stride=stride, pad=(1,1), no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "        bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn2')\n",
    "        act2 = mx.symbol.Activation(data=bn2, act_type='relu', name=name + '_relu2')\n",
    "        conv2 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(3,3), stride=(1,1), pad=(1,1), no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "        if dim_match:\n",
    "            shortcut = data\n",
    "        else:\n",
    "            shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1,1), stride=stride, no_bias=True, workspace=workspace, name=name+'_sc')\n",
    "        return conv2 + shortcut\n",
    "    \n",
    "def cf_unit(res_unit_rgb, res_unit_tir, num_filters=64, name='fusion1_unit_1'):\n",
    "    concat = mx.symbol.Concat(name=name+'_concat', *[res_unit_rgb, res_unit_tir])\n",
    "    bn1 = mx.sym.BatchNorm(data=concat, fix_gamma=False, momentum=0.9, eps=2e-5, name=name + '_bn1')\n",
    "    act1 =  mx.symbol.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "    conv1 = mx.sym.Convolution(act1, num_filter=num_filters, kernel=(3,3), stride=(1,1), pad=(1,1), workspace=256, name=name+'_conv')\n",
    "    return conv1\n",
    "\n",
    "def resnet():\n",
    "    filter_list = [64, 64, 128, 256, 512]\n",
    "    num_stages = 4\n",
    "    units = [2, 2, 2, 2]\n",
    "    bn_mom=0.9\n",
    "    workspace=256\n",
    "    \n",
    "    rgb = mx.sym.Variable(name='rgb')\n",
    "    tir = mx.sym.Variable(name='tir')\n",
    "    label = mx.sym.Variable(name='label')\n",
    "    \n",
    "    # rgb head\n",
    "    rgb = mx.sym.BatchNorm(rgb, fix_gamma=True, eps=2e-5, momentum=bn_mom, name='bn_data')\n",
    "    net_rgb = mx.sym.Convolution(rgb, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3),no_bias=True, name=\"rgb_conv0\", workspace=workspace)\n",
    "    net_rgb = mx.sym.BatchNorm(net_rgb, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn0')\n",
    "    net_rgb = mx.symbol.Activation(net_rgb, act_type='relu', name='relu0')\n",
    "    net_rgb = mx.symbol.Pooling(net_rgb, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type='max')\n",
    "    \n",
    "    # tir head\n",
    "    tir = mx.sym.BatchNorm(tir, fix_gamma=True, eps=2e-5, momentum=bn_mom, name='tir_bn_data')\n",
    "    net_tir = mx.sym.Convolution(tir, num_filter=filter_list[0], kernel=(7, 7), stride=(2,2), pad=(3, 3), no_bias=True, name=\"tir_conv0\", workspace=workspace)\n",
    "    net_tir = mx.sym.BatchNorm(net_tir, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='tir_bn0')\n",
    "    net_tir = mx.symbol.Activation(net_tir, act_type='relu', name='tir_relu0')\n",
    "    net_tir = mx.symbol.Pooling(net_tir, kernel=(3, 3), stride=(2,2), pad=(1,1), pool_type='max')\n",
    "    \n",
    "    # stage 1\n",
    "    net_rgb = residual_unit(net_rgb, filter_list[1], (1,1), False, name='stage1_unit1', workspace=workspace)\n",
    "    net_rgb = residual_unit(net_rgb, filter_list[1], (1,1), True, name='stage1_unit2', workspace=workspace)\n",
    "    net_tir = residual_unit(net_tir, filter_list[1], (1,1), False, name='tir_stage1_unit1', workspace=workspace)\n",
    "    net_tir = residual_unit(net_tir, filter_list[1], (1,1), True, name='tir_stage1_unit2', workspace=workspace)\n",
    "    \n",
    "    # stage 2\n",
    "    net_rgb = residual_unit(net_rgb, filter_list[2], (2,2), False, name='rgb_stage2_unit1', workspace=workspace)\n",
    "    net_rgb = residual_unit(net_rgb, filter_list[2], (1,1), True, name='rgb_stage2_unit2', workspace=workspace)\n",
    "    net_tir = residual_unit(net_tir, filter_list[2], (2,2), False, name='tir_stage2_unit1', workspace=workspace)\n",
    "    net_tir = residual_unit(net_tir, filter_list[2], (1,1), True, name='tir_stage2_unit2', workspace=workspace)    \n",
    "\n",
    "    # stage 3    \n",
    "    net_rgb = residual_unit(net_rgb, filter_list[3], (2,2), False, name='rgb_stage3_unit1', workspace=workspace)\n",
    "    net_tir = residual_unit(net_tir, filter_list[3], (2,2), False, name='tir_stage3_unit1', workspace=workspace)\n",
    "    \n",
    "    # first fusion map\n",
    "    fusion_3_1 = cf_unit(net_rgb.get_internals()[\"rgb_stage3_unit1_relu1_output\"],\n",
    "                         net_tir.get_internals()[\"tir_stage3_unit1_relu1_output\"], \n",
    "                         num_filters=256, name='fusion3_1')\n",
    "    \n",
    "    print_inferred_shape(fusion_3_1, 'stage3_unit1', node_type='spectral')\n",
    "                            \n",
    "    net_rgb = residual_unit(net_rgb, filter_list[3], (1,1), True, name='rgb_stage3_unit2', workspace=workspace) \n",
    "    net_tir = residual_unit(net_tir, filter_list[3], (1,1), True, name='tir_stage3_unit2', workspace=workspace)\n",
    "\n",
    "    # stage 4 \n",
    "    net_rgb = residual_unit(net_rgb, filter_list[4], (2,2), False, name='rgb_stage4_unit1', workspace=workspace)\n",
    "    net_tir = residual_unit(net_tir, filter_list[4], (2,2), False, name='tir_stage4_unit1', workspace=workspace)\n",
    "    # second fusion map\n",
    "    fusion_4_1 = cf_unit(net_rgb.get_internals()[\"rgb_stage4_unit1_relu1_output\"],\n",
    "                     net_tir.get_internals()[\"tir_stage4_unit1_relu1_output\"], \n",
    "                     num_filters=512, name='fusion4_1')\n",
    "    print_inferred_shape(fusion_4_1, 'stage4_unit1',  node_type='spectral')\n",
    "    \n",
    "    net_rgb = residual_unit(net_rgb, filter_list[4], (1,1), True, name='rgb_stage4_unit2', workspace=workspace)\n",
    "#     net_tir = residual_unit(net_tir, filter_list[4], (1,1), True, name='tir_stage4_unit2', workspace=workspace)\n",
    "    \n",
    "    bn1 = mx.sym.BatchNorm(net_rgb, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn1')\n",
    "    relu1 = mx.symbol.Activation(bn1, act_type='relu', name='relu1')\n",
    "    \n",
    "    input_1 = fusion_3_1 #19x19\n",
    "    input_2 = fusion_4_1 #10x10\n",
    "    input_3 = relu1\n",
    "    print_inferred_shape(relu1, 'stage4_unit1',  node_type='rgb')\n",
    "    \n",
    "    # ssd extra layers\n",
    "    conv8_1, relu8_1 = bn_act_conv_layer(input_3, \"8_1\", 256, kernel=(1, 1), pad=(0, 0), stride=(1, 1))\n",
    "    print_inferred_shape(conv8_1, 'stage4_unit1', node_type='rgb')\n",
    "    conv8_2, relu8_2 = bn_act_conv_layer(conv8_1, \"8_2\", 512, kernel=(3, 3), pad=(1, 1), stride=(2, 2))\n",
    "    print_inferred_shape(conv8_2, 'stage4_unit1', node_type='rgb')\n",
    "    conv9_1, relu9_1 = bn_act_conv_layer(conv8_2, \"9_1\", 128, kernel=(1, 1), pad=(0, 0), stride=(1, 1))\n",
    "    print_inferred_shape(conv9_1, 'stage4_unit1', node_type='rgb')\n",
    "    conv9_2, relu9_2 = bn_act_conv_layer(conv9_1, \"9_2\", 256, kernel=(3, 3), pad=(1, 1), stride=(2, 2))\n",
    "    print_inferred_shape(conv9_2, 'stage4_unit1', node_type='rgb')\n",
    "    conv10_1, relu10_1 = bn_act_conv_layer(conv9_2, \"10_1\", 128, kernel=(1, 1), pad=(0, 0), stride=(1, 1))\n",
    "    print_inferred_shape(conv10_1, 'stage4_unit1', node_type='rgb')\n",
    "    conv10_2, relu10_2 = bn_act_conv_layer(conv10_1, \"10_2\", 256, kernel=(3, 3), pad=(1, 1), stride=(2, 2))\n",
    "    print_inferred_shape(conv10_2, 'stage4_unit1', node_type='rgb')\n",
    "\n",
    "    # global Pooling\n",
    "    pool10 = mx.symbol.Pooling(data=conv10_2, pool_type=\"avg\", global_pool=True, kernel=(1, 1), name='pool10')\n",
    "    print_inferred_shape(pool10, 'stage4_unit1', node_type='rgb')\n",
    "    \n",
    "    # with feature maps: ssd_input\n",
    "    from_layers = [input_1, input_2, conv8_2, conv9_2, conv10_2, pool10]\n",
    "    \n",
    "    return mx.symbol.Group(from_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1L, 256L, 38L, 38L)]\n",
      "[(1L, 512L, 19L, 19L)]\n",
      "[(1L, 512L, 10L, 10L)]\n",
      "[(1L, 256L, 10L, 10L)]\n",
      "[(1L, 512L, 5L, 5L)]\n",
      "[(1L, 128L, 5L, 5L)]\n",
      "[(1L, 256L, 3L, 3L)]\n",
      "[(1L, 128L, 3L, 3L)]\n",
      "[(1L, 256L, 2L, 2L)]\n",
      "[(1L, 256L, 1L, 1L)]\n"
     ]
    }
   ],
   "source": [
    "plot_network(resnet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data', {'conv5_bias': <NDArray 256 @cpu(0)>, 'conv4_bias': <NDArray 384 @cpu(0)>, 'conv1_bias': <NDArray 96 @cpu(0)>, 'conv3_weight': <NDArray 384x256x3x3 @cpu(0)>, 'conv5_weight': <NDArray 256x192x3x3 @cpu(0)>, 'conv4_weight': <NDArray 384x192x3x3 @cpu(0)>, 'conv2_bias': <NDArray 256 @cpu(0)>, 'conv2_weight': <NDArray 256x48x5x5 @cpu(0)>, 'conv3_bias': <NDArray 384 @cpu(0)>, 'conv1_weight': <NDArray 96x3x11x11 @cpu(0)>}, {'conv5_bias': <NDArray 256 @cpu(0)>, 'conv4_bias': <NDArray 384 @cpu(0)>, 'conv1_bias': <NDArray 96 @cpu(0)>, 'conv3_weight': <NDArray 384x256x3x3 @cpu(0)>, 'conv5_weight': <NDArray 256x192x3x3 @cpu(0)>, 'conv4_weight': <NDArray 384x192x3x3 @cpu(0)>, 'conv2_bias': <NDArray 256 @cpu(0)>, 'conv2_weight': <NDArray 256x48x5x5 @cpu(0)>, 'conv3_bias': <NDArray 384 @cpu(0)>, 'conv1_weight': <NDArray 96x3x11x11 @cpu(0)>})\n",
      "('conv1_weight', {}, {})\n"
     ]
    }
   ],
   "source": [
    "args = dict(zip(model.symbol.list_arguments(), model.get_params()))\n",
    "\n",
    "for name in args:\n",
    "    print(name, args[name], args[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new network params\n",
    "spectral_net_params = dict()\n",
    "\n",
    "# read original resnet params\n",
    "net_params = mx.initializer.Load('resnet-0000.params')\n",
    "\n",
    "# read trained ssd-resnet 0.68\n",
    "net_params_ssd = mx.initializer.Load('ssd_300-0300.params')\n",
    "\n",
    "# initiliaze weights\n",
    "for par in net_params.param:\n",
    "    if par not in ['fc1_weight', 'fc1_bias', 'bn1', 'bn1_beta', 'bn1_gamma', 'bn1_moving_mean', 'bn1_moving_var']:\n",
    "        spectral_net_params['rgb_' + par] = net_params_ssd.param[par]\n",
    "        spectral_net_params['tir_' + par] = net_params_ssd.param[par]\n",
    "    elif par in ['bn1', 'bn1_beta', 'bn1_gamma', 'bn1_moving_mean', 'bn1_moving_var']:\n",
    "        spectral_net_params[par] = net_params_ssd.param[par]\n",
    "        \n",
    "# initiliaze fusion conv\n",
    "net = resnet()\n",
    "ex = net.simple_bind(ctx=mx.cpu(), rgb=(1, 3, 300, 300), tir=(1,1,300,300))\n",
    "args = dict(zip(model.symbol.list_arguments(), ex.arg_arrays))\n",
    "\n",
    "# for name in args:\n",
    "#     if name.startswith('fusion'):\n",
    "#         spectral_net_params[name] = mx.random.uniform(-0.1, 0.1, data.shape)\n",
    "#         print(name, args[name].shape)\n",
    "        \n",
    "# for name in args:\n",
    "#     data = args[name]\n",
    "#     if 'weight' in name:\n",
    "#         data[:] = mx.random.uniform(-0.1, 0.1, data.shape)\n",
    "#     if 'bias' in name:\n",
    "#         data[:] = 0\n",
    "#     spectral_net_params[name] = data\n",
    "\n",
    "\n",
    "# take all values for red chanell since it close to TIR\n",
    "spectral_net_params['tir_conv0_weight'] = mx.nd.array(spectral_net_params['tir_conv0_weight'].asnumpy()[:, :1, :, :])\n",
    "spectral_net_params['tir_bn_data_gamma'] = mx.nd.array(spectral_net_params['tir_bn_data_gamma'].asnumpy()[:1])\n",
    "spectral_net_params['tir_bn_data_beta'] = mx.nd.array(spectral_net_params['tir_bn_data_beta'].asnumpy()[:1])\n",
    "spectral_net_params['tir_bn_data_moving_var'] = mx.nd.array(spectral_net_params['tir_bn_data_moving_var'].asnumpy()[:1])\n",
    "spectral_net_params['tir_bn_data_moving_mean'] = mx.nd.array(spectral_net_params['tir_bn_data_moving_mean'].asnumpy()[:1])\n",
    "\n",
    "net_params.param = spectral_net_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1L, 256L, 38L, 38L)]\n",
      "[(1L, 512L, 19L, 19L)]\n",
      "[(1L, 512L, 10L, 10L)]\n",
      "[(1L, 256L, 10L, 10L)]\n",
      "[(1L, 512L, 5L, 5L)]\n",
      "[(1L, 128L, 5L, 5L)]\n",
      "[(1L, 256L, 3L, 3L)]\n",
      "[(1L, 128L, 3L, 3L)]\n",
      "[(1L, 256L, 2L, 2L)]\n",
      "[(1L, 256L, 1L, 1L)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/mxnet/python/mxnet/module/base_module.py:52: UserWarning: \u001b[91mYou created Module with Module(..., label_names=['softmax_label']) but input with name 'softmax_label' is not found in symbol.list_arguments(). Did you mean one of:\n",
      "\trgb\n",
      "\ttir\u001b[0m\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = mx.mod.Module(symbol=resnet(), data_names=['rgb', 'tir'])\n",
    "model.bind(data_shapes=[('rgb', (1, 3, 300, 300)), ('tir', (1, 1, 300, 300))])\n",
    "model.init_params(arg_params=net_params.param, allow_missing=True, initializer=mx.initializer.Xavier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/mxnet/python/mxnet/module/base_module.py:52: UserWarning: \u001b[91mYou created Module with Module(..., label_names=['softmax_label']) but input with name 'softmax_label' is not found in symbol.list_arguments(). Did you mean one of:\n",
      "\trgb\n",
      "\ttir\u001b[0m\n",
      "  warnings.warn(msg)\n",
      "/home/home/mxnet/python/mxnet/module/base_module.py:64: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "net_params_spectral = mx.initializer.Load('ssd_300-0028.params')\n",
    "\n",
    "model = mx.mod.Module(symbol=resnet(), data_names=['rgb', 'tir'])\n",
    "model.bind(data_shapes=[('rgb', (1, 3, 300, 300)), ('tir', (1, 1, 300, 300))])\n",
    "model.init_params(net_params_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_net(model, 'multispectral_resnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained for SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_params = mx.initializer.Load('NETS/caltech_kaist/ssd_300-0806.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn0_beta (64L,)\n",
      "bn0_gamma (64L,)\n",
      "bn0_moving_mean (64L,)\n",
      "bn0_moving_var (64L,)\n",
      "bn10_1_beta (256L,)\n",
      "bn10_1_gamma (256L,)\n",
      "bn10_1_moving_mean (256L,)\n",
      "bn10_1_moving_var (256L,)\n",
      "bn10_2_beta (128L,)\n",
      "bn10_2_gamma (128L,)\n",
      "bn10_2_moving_mean (128L,)\n",
      "bn10_2_moving_var (128L,)\n",
      "bn1_beta (512L,)\n",
      "bn1_gamma (512L,)\n",
      "bn1_moving_mean (512L,)\n",
      "bn1_moving_var (512L,)\n",
      "bn8_1_beta (512L,)\n",
      "bn8_1_gamma (512L,)\n",
      "bn8_1_moving_mean (512L,)\n",
      "bn8_1_moving_var (512L,)\n",
      "bn8_2_beta (256L,)\n",
      "bn8_2_gamma (256L,)\n",
      "bn8_2_moving_mean (256L,)\n",
      "bn8_2_moving_var (256L,)\n",
      "bn9_1_beta (512L,)\n",
      "bn9_1_gamma (512L,)\n",
      "bn9_1_moving_mean (512L,)\n",
      "bn9_1_moving_var (512L,)\n",
      "bn9_2_beta (128L,)\n",
      "bn9_2_gamma (128L,)\n",
      "bn9_2_moving_mean (128L,)\n",
      "bn9_2_moving_var (128L,)\n",
      "bn_data_beta (3L,)\n",
      "bn_data_gamma (3L,)\n",
      "bn_data_moving_mean (3L,)\n",
      "bn_data_moving_var (3L,)\n",
      "conv0_weight (64L, 3L, 7L, 7L)\n",
      "conv10_1_bias (128L,)\n",
      "conv10_1_weight (128L, 256L, 1L, 1L)\n",
      "conv10_2_bias (256L,)\n",
      "conv10_2_cls_pred_conv_bias (126L,)\n",
      "conv10_2_cls_pred_conv_weight (126L, 256L, 3L, 3L)\n",
      "conv10_2_loc_pred_conv_bias (24L,)\n",
      "conv10_2_loc_pred_conv_weight (24L, 256L, 3L, 3L)\n",
      "conv10_2_weight (256L, 128L, 3L, 3L)\n",
      "conv8_1_bias (256L,)\n",
      "conv8_1_weight (256L, 512L, 1L, 1L)\n",
      "conv8_2_bias (512L,)\n",
      "conv8_2_cls_pred_conv_bias (126L,)\n",
      "conv8_2_cls_pred_conv_weight (126L, 512L, 3L, 3L)\n",
      "conv8_2_loc_pred_conv_bias (24L,)\n",
      "conv8_2_loc_pred_conv_weight (24L, 512L, 3L, 3L)\n",
      "conv8_2_weight (512L, 256L, 3L, 3L)\n",
      "conv9_1_bias (128L,)\n",
      "conv9_1_weight (128L, 512L, 1L, 1L)\n",
      "conv9_2_bias (256L,)\n",
      "conv9_2_cls_pred_conv_bias (126L,)\n",
      "conv9_2_cls_pred_conv_weight (126L, 256L, 3L, 3L)\n",
      "conv9_2_loc_pred_conv_bias (24L,)\n",
      "conv9_2_loc_pred_conv_weight (24L, 256L, 3L, 3L)\n",
      "conv9_2_weight (256L, 128L, 3L, 3L)\n",
      "pool10_cls_pred_conv_bias (126L,)\n",
      "pool10_cls_pred_conv_weight (126L, 256L, 3L, 3L)\n",
      "pool10_loc_pred_conv_bias (24L,)\n",
      "pool10_loc_pred_conv_weight (24L, 256L, 3L, 3L)\n",
      "stage1_unit1_bn1_beta (64L,)\n",
      "stage1_unit1_bn1_gamma (64L,)\n",
      "stage1_unit1_bn1_moving_mean (64L,)\n",
      "stage1_unit1_bn1_moving_var (64L,)\n",
      "stage1_unit1_bn2_beta (64L,)\n",
      "stage1_unit1_bn2_gamma (64L,)\n",
      "stage1_unit1_bn2_moving_mean (64L,)\n",
      "stage1_unit1_bn2_moving_var (64L,)\n",
      "stage1_unit1_conv1_weight (64L, 64L, 3L, 3L)\n",
      "stage1_unit1_conv2_weight (64L, 64L, 3L, 3L)\n",
      "stage1_unit1_sc_weight (64L, 64L, 1L, 1L)\n",
      "stage1_unit2_bn1_beta (64L,)\n",
      "stage1_unit2_bn1_gamma (64L,)\n",
      "stage1_unit2_bn1_moving_mean (64L,)\n",
      "stage1_unit2_bn1_moving_var (64L,)\n",
      "stage1_unit2_bn2_beta (64L,)\n",
      "stage1_unit2_bn2_gamma (64L,)\n",
      "stage1_unit2_bn2_moving_mean (64L,)\n",
      "stage1_unit2_bn2_moving_var (64L,)\n",
      "stage1_unit2_conv1_weight (64L, 64L, 3L, 3L)\n",
      "stage1_unit2_conv2_weight (64L, 64L, 3L, 3L)\n",
      "stage2_unit1_bn1_beta (64L,)\n",
      "stage2_unit1_bn1_gamma (64L,)\n",
      "stage2_unit1_bn1_moving_mean (64L,)\n",
      "stage2_unit1_bn1_moving_var (64L,)\n",
      "stage2_unit1_bn2_beta (128L,)\n",
      "stage2_unit1_bn2_gamma (128L,)\n",
      "stage2_unit1_bn2_moving_mean (128L,)\n",
      "stage2_unit1_bn2_moving_var (128L,)\n",
      "stage2_unit1_conv1_weight (128L, 64L, 3L, 3L)\n",
      "stage2_unit1_conv2_weight (128L, 128L, 3L, 3L)\n",
      "stage2_unit1_sc_weight (128L, 64L, 1L, 1L)\n",
      "stage2_unit2_bn1_beta (128L,)\n",
      "stage2_unit2_bn1_gamma (128L,)\n",
      "stage2_unit2_bn1_moving_mean (128L,)\n",
      "stage2_unit2_bn1_moving_var (128L,)\n",
      "stage2_unit2_bn2_beta (128L,)\n",
      "stage2_unit2_bn2_gamma (128L,)\n",
      "stage2_unit2_bn2_moving_mean (128L,)\n",
      "stage2_unit2_bn2_moving_var (128L,)\n",
      "stage2_unit2_conv1_weight (128L, 128L, 3L, 3L)\n",
      "stage2_unit2_conv2_weight (128L, 128L, 3L, 3L)\n",
      "stage3_unit1_bn1_beta (128L,)\n",
      "stage3_unit1_bn1_gamma (128L,)\n",
      "stage3_unit1_bn1_moving_mean (128L,)\n",
      "stage3_unit1_bn1_moving_var (128L,)\n",
      "stage3_unit1_bn2_beta (256L,)\n",
      "stage3_unit1_bn2_gamma (256L,)\n",
      "stage3_unit1_bn2_moving_mean (256L,)\n",
      "stage3_unit1_bn2_moving_var (256L,)\n",
      "stage3_unit1_conv1_weight (256L, 128L, 3L, 3L)\n",
      "stage3_unit1_conv2_weight (256L, 256L, 3L, 3L)\n",
      "stage3_unit1_relu1_cls_pred_conv_bias (63L,)\n",
      "stage3_unit1_relu1_cls_pred_conv_weight (63L, 128L, 3L, 3L)\n",
      "stage3_unit1_relu1_loc_pred_conv_bias (12L,)\n",
      "stage3_unit1_relu1_loc_pred_conv_weight (12L, 128L, 3L, 3L)\n",
      "stage3_unit1_relu1_scale (1L, 128L, 1L, 1L)\n",
      "stage3_unit1_sc_weight (256L, 128L, 1L, 1L)\n",
      "stage3_unit2_bn1_beta (256L,)\n",
      "stage3_unit2_bn1_gamma (256L,)\n",
      "stage3_unit2_bn1_moving_mean (256L,)\n",
      "stage3_unit2_bn1_moving_var (256L,)\n",
      "stage3_unit2_bn2_beta (256L,)\n",
      "stage3_unit2_bn2_gamma (256L,)\n",
      "stage3_unit2_bn2_moving_mean (256L,)\n",
      "stage3_unit2_bn2_moving_var (256L,)\n",
      "stage3_unit2_conv1_weight (256L, 256L, 3L, 3L)\n",
      "stage3_unit2_conv2_weight (256L, 256L, 3L, 3L)\n",
      "stage4_unit1_bn1_beta (256L,)\n",
      "stage4_unit1_bn1_gamma (256L,)\n",
      "stage4_unit1_bn1_moving_mean (256L,)\n",
      "stage4_unit1_bn1_moving_var (256L,)\n",
      "stage4_unit1_bn2_beta (512L,)\n",
      "stage4_unit1_bn2_gamma (512L,)\n",
      "stage4_unit1_bn2_moving_mean (512L,)\n",
      "stage4_unit1_bn2_moving_var (512L,)\n",
      "stage4_unit1_conv1_weight (512L, 256L, 3L, 3L)\n",
      "stage4_unit1_conv2_weight (512L, 512L, 3L, 3L)\n",
      "stage4_unit1_relu1_cls_pred_conv_bias (126L,)\n",
      "stage4_unit1_relu1_cls_pred_conv_weight (126L, 256L, 3L, 3L)\n",
      "stage4_unit1_relu1_loc_pred_conv_bias (24L,)\n",
      "stage4_unit1_relu1_loc_pred_conv_weight (24L, 256L, 3L, 3L)\n",
      "stage4_unit1_sc_weight (512L, 256L, 1L, 1L)\n",
      "stage4_unit2_bn1_beta (512L,)\n",
      "stage4_unit2_bn1_gamma (512L,)\n",
      "stage4_unit2_bn1_moving_mean (512L,)\n",
      "stage4_unit2_bn1_moving_var (512L,)\n",
      "stage4_unit2_bn2_beta (512L,)\n",
      "stage4_unit2_bn2_gamma (512L,)\n",
      "stage4_unit2_bn2_moving_mean (512L,)\n",
      "stage4_unit2_bn2_moving_var (512L,)\n",
      "stage4_unit2_conv1_weight (512L, 512L, 3L, 3L)\n",
      "stage4_unit2_conv2_weight (512L, 512L, 3L, 3L)\n"
     ]
    }
   ],
   "source": [
    "print_net_params(net_params.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv8_2_loc_pred_conv_weight (24, 512, 3, 3)\n",
      "conv8_2_cls_pred_conv_weight (126, 512, 3, 3)\n",
      "conv10_2_loc_pred_conv_bias (24,)\n",
      "stage3_unit1_relu1_loc_pred_conv_bias (12,)\n",
      "conv8_2_cls_pred_conv_bias (126,)\n",
      "conv10_2_cls_pred_conv_bias (126,)\n",
      "conv9_2_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "stage4_unit1_relu1_cls_pred_conv_bias (126,)\n",
      "conv10_2_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "conv9_2_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "stage4_unit1_relu1_loc_pred_conv_bias (24,)\n",
      "pool10_loc_pred_conv_bias (24,)\n",
      "stage3_unit1_relu1_cls_pred_conv_bias (63,)\n",
      "stage3_unit1_relu1_cls_pred_conv_weight (63, 128, 3, 3)\n",
      "conv8_2_loc_pred_conv_bias (24,)\n",
      "pool10_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "conv9_2_cls_pred_conv_bias (126,)\n",
      "stage4_unit1_relu1_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "conv10_2_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "pool10_cls_pred_conv_bias (126,)\n",
      "pool10_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "stage4_unit1_relu1_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "stage3_unit1_relu1_loc_pred_conv_weight (12, 128, 3, 3)\n",
      "conv9_2_loc_pred_conv_bias (24,)\n"
     ]
    }
   ],
   "source": [
    "cls_loc_weights = []\n",
    "for name in net_params.param:\n",
    "    if 'cls' in name.split('_'):\n",
    "        cls_loc_weights.append(name)\n",
    "#         print name\n",
    "        \n",
    "    if 'loc' in name.split('_'):\n",
    "        cls_loc_weights.append(name)\n",
    "#         print name\n",
    "\n",
    "for name in cls_loc_weights:\n",
    "    print name, net_params.param[name].asnumpy().shape\n",
    "    del net_params.param[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home/mxnet/python/mxnet/module/base_module.py:52: UserWarning: \u001b[91mYou created Module with Module(..., label_names=['softmax_label']) but input with name 'softmax_label' is not found in symbol.list_arguments(). Did you mean one of:\n",
      "\tdata\u001b[0m\n",
      "  warnings.warn(msg)\n",
      "/home/home/mxnet/python/mxnet/module/base_module.py:64: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['softmax_label'])\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = mx.mod.Module(symbol=resnet())\n",
    "model.bind(data_shapes=[('data', (1, 3, 300, 300))])\n",
    "model.init_params(net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_net(model, 'resnet_caltech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TIR Resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def bn_act_conv_layer(from_layer, name, num_filter, kernel=(1,1), pad=(0,0), stride=(1,1)):\n",
    "    bn = mx.symbol.BatchNorm(data=from_layer, name=\"bn{}\".format(name))\n",
    "    relu = mx.symbol.Activation(data=bn, act_type='relu')\n",
    "    conv = mx.symbol.Convolution(data=relu, kernel=kernel, pad=pad, stride=stride, num_filter=num_filter, name=\"conv{}\".format(name))\n",
    "    return conv, relu\n",
    "\n",
    "\n",
    "def residual_unit(data, num_filter, stride, dim_match, name, bn_mom=0.9, workspace=256):\n",
    "    bn1 = mx.sym.BatchNorm(data=data, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn1')\n",
    "    act1 = mx.symbol.Activation(data=bn1, act_type='relu', name=name + '_relu1')\n",
    "    conv1 = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(3, 3), stride=stride, pad=(1, 1),\n",
    "                               no_bias=True, workspace=workspace, name=name + '_conv1')\n",
    "    bn2 = mx.sym.BatchNorm(data=conv1, fix_gamma=False, momentum=bn_mom, eps=2e-5, name=name + '_bn2')\n",
    "    act2 = mx.symbol.Activation(data=bn2, act_type='relu', name=name + '_relu2')\n",
    "    conv2 = mx.sym.Convolution(data=act2, num_filter=num_filter, kernel=(3, 3), stride=(1, 1), pad=(1, 1), no_bias=True, workspace=workspace, name=name + '_conv2')\n",
    "    if dim_match:\n",
    "        shortcut = data\n",
    "    else:\n",
    "        shortcut = mx.sym.Convolution(data=act1, num_filter=num_filter, kernel=(1, 1), stride=stride, no_bias=True, workspace=workspace, name=name + '_sc')\n",
    "    return conv2 + shortcut\n",
    "\n",
    "\n",
    "def resnet():\n",
    "    filter_list = [64, 64, 128, 256, 512]\n",
    "    bn_mom = 0.9\n",
    "    workspace = 256\n",
    "\n",
    "    data = mx.sym.Variable(name='data')\n",
    "    data = mx.sym.BatchNorm(data=data, fix_gamma=True, eps=2e-5, momentum=bn_mom, name='bn_data')\n",
    "    net = mx.sym.Convolution(data, num_filter=filter_list[0], kernel=(7, 7), stride=(2, 2), pad=(3, 3), no_bias=True, name=\"conv0\", workspace=workspace)\n",
    "    net = mx.sym.BatchNorm(net, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn0')\n",
    "    net = mx.symbol.Activation(net, act_type='relu', name='relu0')\n",
    "    net = mx.symbol.Pooling(net, kernel=(3, 3), stride=(2, 2), pad=(1, 1), pool_type='max')\n",
    "\n",
    "    # stage 1\n",
    "    net = residual_unit(net, filter_list[1], (1, 1), False, name='stage1_unit1', workspace=workspace)\n",
    "    net = residual_unit(net, filter_list[1], (1, 1), True, name='stage1_unit2', workspace=workspace)\n",
    "    # stage 2\n",
    "    net = residual_unit(net, filter_list[2], (2, 2), False, name='stage2_unit1', workspace=workspace)\n",
    "    net = residual_unit(net, filter_list[2], (1, 1), True, name='stage2_unit2', workspace=workspace)\n",
    "    # stage 3\n",
    "    net = residual_unit(net, filter_list[3], (2, 2), False, name='stage3_unit1', workspace=workspace)\n",
    "    net = residual_unit(net, filter_list[3], (1, 1), True, name='stage3_unit2', workspace=workspace)\n",
    "    # stage 4\n",
    "    net = residual_unit(net, filter_list[4], (2, 2), False, name='stage4_unit1', workspace=workspace)\n",
    "    net = residual_unit(net, filter_list[4], (1, 1), True, name='stage4_unit2', workspace=workspace)\n",
    "\n",
    "    bn1 = mx.sym.BatchNorm(data=net, fix_gamma=False, eps=2e-5, momentum=bn_mom, name='bn1')\n",
    "    relu1 = mx.symbol.Activation(data=bn1, act_type='relu', name='relu1')\n",
    "    \n",
    "    input_3 = relu1 # 10x10\n",
    "    internals = input_3.get_internals()\n",
    "    input_1 = internals['stage3_unit1_relu1_output']  # 38x38\n",
    "    input_2 = internals['stage4_unit1_relu1_output']  # 19X19\n",
    "    \n",
    "     # ssd extra layers\n",
    "    conv8_1, elu8_1 = bn_act_conv_layer(input_3, \"8_1\", 256, kernel=(1, 1), pad=(0, 0), stride=(1, 1))\n",
    "    conv8_2, elu8_2 = bn_act_conv_layer(conv8_1, \"8_2\", 512, kernel=(3, 3), pad=(1, 1), stride=(2, 2))\n",
    "    conv9_1, elu9_1 = bn_act_conv_layer(conv8_2, \"9_1\", 128, kernel=(1, 1), pad=(0, 0), stride=(1, 1))\n",
    "    conv9_2, elu9_2 = bn_act_conv_layer(conv9_1, \"9_2\", 256, kernel=(3, 3), pad=(1, 1), stride=(2, 2))\n",
    "    conv10_1, elu10_1 = bn_act_conv_layer(conv9_2, \"10_1\", 128, kernel=(1, 1), pad=(0, 0), stride=(1, 1))\n",
    "    conv10_2, elu10_2 = bn_act_conv_layer(conv10_1, \"10_2\", 256, kernel=(3, 3), pad=(1, 1), stride=(2, 2))\n",
    "\n",
    "    # global Pooling\n",
    "    pool10 = mx.symbol.Pooling(data=conv10_2, pool_type=\"avg\", global_pool=True, kernel=(1, 1), name='pool10')\n",
    "    return pool10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get weights of pretrained model for PASCAL VOC and adapt it to single channel input\n",
    "# read trained ssd-resnet 0.68\n",
    "net_params = mx.initializer.Load('ssd_300-0300.params')\n",
    "\n",
    "# take all values for red chanell, since it closer to TIR\n",
    "# net_params.param['conv0_weight'] = mx.nd.array(net_params.param['conv0_weight'].asnumpy()[:, :1, :, :])\n",
    "# net_params.param['bn_data_gamma'] = mx.nd.array(net_params.param['bn_data_gamma'].asnumpy()[:1])\n",
    "# net_params.param['bn_data_beta'] = mx.nd.array(net_params.param['bn_data_beta'].asnumpy()[:1])\n",
    "# net_params.param['bn_data_moving_var'] = mx.nd.array(net_params.param['bn_data_moving_var'].asnumpy()[:1])\n",
    "# net_params.param['bn_data_moving_mean'] = mx.nd.array(net_params.param['bn_data_moving_mean'].asnumpy()[:1])\n",
    "\n",
    "# specify training layers names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv8_2_loc_pred_conv_weight (24, 512, 3, 3)\n",
      "conv8_2_cls_pred_conv_weight (126, 512, 3, 3)\n",
      "conv10_2_loc_pred_conv_bias (24,)\n",
      "stage3_unit1_relu1_loc_pred_conv_bias (12,)\n",
      "conv8_2_cls_pred_conv_bias (126,)\n",
      "conv10_2_cls_pred_conv_bias (126,)\n",
      "conv9_2_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "stage4_unit1_relu1_cls_pred_conv_bias (126,)\n",
      "conv10_2_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "conv9_2_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "stage4_unit1_relu1_loc_pred_conv_bias (24,)\n",
      "pool10_loc_pred_conv_bias (24,)\n",
      "stage3_unit1_relu1_cls_pred_conv_bias (63,)\n",
      "stage3_unit1_relu1_cls_pred_conv_weight (63, 128, 3, 3)\n",
      "conv8_2_loc_pred_conv_bias (24,)\n",
      "pool10_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "conv9_2_cls_pred_conv_bias (126,)\n",
      "stage4_unit1_relu1_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "conv10_2_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "pool10_cls_pred_conv_bias (126,)\n",
      "pool10_loc_pred_conv_weight (24, 256, 3, 3)\n",
      "stage4_unit1_relu1_cls_pred_conv_weight (126, 256, 3, 3)\n",
      "stage3_unit1_relu1_loc_pred_conv_weight (12, 128, 3, 3)\n",
      "conv9_2_loc_pred_conv_bias (24,)\n"
     ]
    }
   ],
   "source": [
    "for i in net_params.param:\n",
    "#     print i\n",
    "#     print i.split('_')\n",
    "    if 'loc' in i.split('_') or 'pred' in i.split('_'):\n",
    "        print i, net_params.param[i].asnumpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize model with new params to check correctness\n",
    "model = mx.mod.Module(symbol=resnet())\n",
    "model.bind(data_shapes=[('data', (1, 3, 300, 300))])\n",
    "model.init_params(net_params)\n",
    "\n",
    "# save tir model\n",
    "save_net(model, 'resnet_rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB_TIR Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_params = mx.initializer.Load('resnet_tir-0001.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0_beta': <NDArray 64 @cpu(0)>,\n",
       " 'bn0_gamma': <NDArray 64 @cpu(0)>,\n",
       " 'bn0_moving_mean': <NDArray 64 @cpu(0)>,\n",
       " 'bn0_moving_var': <NDArray 64 @cpu(0)>,\n",
       " 'bn10_1_beta': <NDArray 256 @cpu(0)>,\n",
       " 'bn10_1_gamma': <NDArray 256 @cpu(0)>,\n",
       " 'bn10_1_moving_mean': <NDArray 256 @cpu(0)>,\n",
       " 'bn10_1_moving_var': <NDArray 256 @cpu(0)>,\n",
       " 'bn10_2_beta': <NDArray 128 @cpu(0)>,\n",
       " 'bn10_2_gamma': <NDArray 128 @cpu(0)>,\n",
       " 'bn10_2_moving_mean': <NDArray 128 @cpu(0)>,\n",
       " 'bn10_2_moving_var': <NDArray 128 @cpu(0)>,\n",
       " 'bn1_beta': <NDArray 512 @cpu(0)>,\n",
       " 'bn1_gamma': <NDArray 512 @cpu(0)>,\n",
       " 'bn1_moving_mean': <NDArray 512 @cpu(0)>,\n",
       " 'bn1_moving_var': <NDArray 512 @cpu(0)>,\n",
       " 'bn8_1_beta': <NDArray 512 @cpu(0)>,\n",
       " 'bn8_1_gamma': <NDArray 512 @cpu(0)>,\n",
       " 'bn8_1_moving_mean': <NDArray 512 @cpu(0)>,\n",
       " 'bn8_1_moving_var': <NDArray 512 @cpu(0)>,\n",
       " 'bn8_2_beta': <NDArray 256 @cpu(0)>,\n",
       " 'bn8_2_gamma': <NDArray 256 @cpu(0)>,\n",
       " 'bn8_2_moving_mean': <NDArray 256 @cpu(0)>,\n",
       " 'bn8_2_moving_var': <NDArray 256 @cpu(0)>,\n",
       " 'bn9_1_beta': <NDArray 512 @cpu(0)>,\n",
       " 'bn9_1_gamma': <NDArray 512 @cpu(0)>,\n",
       " 'bn9_1_moving_mean': <NDArray 512 @cpu(0)>,\n",
       " 'bn9_1_moving_var': <NDArray 512 @cpu(0)>,\n",
       " 'bn9_2_beta': <NDArray 128 @cpu(0)>,\n",
       " 'bn9_2_gamma': <NDArray 128 @cpu(0)>,\n",
       " 'bn9_2_moving_mean': <NDArray 128 @cpu(0)>,\n",
       " 'bn9_2_moving_var': <NDArray 128 @cpu(0)>,\n",
       " 'bn_data_beta': <NDArray 1 @cpu(0)>,\n",
       " 'bn_data_gamma': <NDArray 1 @cpu(0)>,\n",
       " 'bn_data_moving_mean': <NDArray 1 @cpu(0)>,\n",
       " 'bn_data_moving_var': <NDArray 1 @cpu(0)>,\n",
       " 'conv0_weight': <NDArray 64x1x7x7 @cpu(0)>,\n",
       " 'conv10_1_bias': <NDArray 128 @cpu(0)>,\n",
       " 'conv10_1_weight': <NDArray 128x256x1x1 @cpu(0)>,\n",
       " 'conv10_2_bias': <NDArray 256 @cpu(0)>,\n",
       " 'conv10_2_weight': <NDArray 256x128x3x3 @cpu(0)>,\n",
       " 'conv8_1_bias': <NDArray 256 @cpu(0)>,\n",
       " 'conv8_1_weight': <NDArray 256x512x1x1 @cpu(0)>,\n",
       " 'conv8_2_bias': <NDArray 512 @cpu(0)>,\n",
       " 'conv8_2_weight': <NDArray 512x256x3x3 @cpu(0)>,\n",
       " 'conv9_1_bias': <NDArray 128 @cpu(0)>,\n",
       " 'conv9_1_weight': <NDArray 128x512x1x1 @cpu(0)>,\n",
       " 'conv9_2_bias': <NDArray 256 @cpu(0)>,\n",
       " 'conv9_2_weight': <NDArray 256x128x3x3 @cpu(0)>,\n",
       " 'stage1_unit1_bn1_beta': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn1_gamma': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn1_moving_mean': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn1_moving_var': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn2_beta': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn2_gamma': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn2_moving_mean': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_bn2_moving_var': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit1_conv1_weight': <NDArray 64x64x3x3 @cpu(0)>,\n",
       " 'stage1_unit1_conv2_weight': <NDArray 64x64x3x3 @cpu(0)>,\n",
       " 'stage1_unit1_sc_weight': <NDArray 64x64x1x1 @cpu(0)>,\n",
       " 'stage1_unit2_bn1_beta': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn1_gamma': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn1_moving_mean': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn1_moving_var': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn2_beta': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn2_gamma': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn2_moving_mean': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_bn2_moving_var': <NDArray 64 @cpu(0)>,\n",
       " 'stage1_unit2_conv1_weight': <NDArray 64x64x3x3 @cpu(0)>,\n",
       " 'stage1_unit2_conv2_weight': <NDArray 64x64x3x3 @cpu(0)>,\n",
       " 'stage2_unit1_bn1_beta': <NDArray 64 @cpu(0)>,\n",
       " 'stage2_unit1_bn1_gamma': <NDArray 64 @cpu(0)>,\n",
       " 'stage2_unit1_bn1_moving_mean': <NDArray 64 @cpu(0)>,\n",
       " 'stage2_unit1_bn1_moving_var': <NDArray 64 @cpu(0)>,\n",
       " 'stage2_unit1_bn2_beta': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit1_bn2_gamma': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit1_bn2_moving_mean': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit1_bn2_moving_var': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit1_conv1_weight': <NDArray 128x64x3x3 @cpu(0)>,\n",
       " 'stage2_unit1_conv2_weight': <NDArray 128x128x3x3 @cpu(0)>,\n",
       " 'stage2_unit1_sc_weight': <NDArray 128x64x1x1 @cpu(0)>,\n",
       " 'stage2_unit2_bn1_beta': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn1_gamma': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn1_moving_mean': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn1_moving_var': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn2_beta': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn2_gamma': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn2_moving_mean': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_bn2_moving_var': <NDArray 128 @cpu(0)>,\n",
       " 'stage2_unit2_conv1_weight': <NDArray 128x128x3x3 @cpu(0)>,\n",
       " 'stage2_unit2_conv2_weight': <NDArray 128x128x3x3 @cpu(0)>,\n",
       " 'stage3_unit1_bn1_beta': <NDArray 128 @cpu(0)>,\n",
       " 'stage3_unit1_bn1_gamma': <NDArray 128 @cpu(0)>,\n",
       " 'stage3_unit1_bn1_moving_mean': <NDArray 128 @cpu(0)>,\n",
       " 'stage3_unit1_bn1_moving_var': <NDArray 128 @cpu(0)>,\n",
       " 'stage3_unit1_bn2_beta': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit1_bn2_gamma': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit1_bn2_moving_mean': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit1_bn2_moving_var': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit1_conv1_weight': <NDArray 256x128x3x3 @cpu(0)>,\n",
       " 'stage3_unit1_conv2_weight': <NDArray 256x256x3x3 @cpu(0)>,\n",
       " 'stage3_unit1_sc_weight': <NDArray 256x128x1x1 @cpu(0)>,\n",
       " 'stage3_unit2_bn1_beta': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn1_gamma': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn1_moving_mean': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn1_moving_var': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn2_beta': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn2_gamma': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn2_moving_mean': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_bn2_moving_var': <NDArray 256 @cpu(0)>,\n",
       " 'stage3_unit2_conv1_weight': <NDArray 256x256x3x3 @cpu(0)>,\n",
       " 'stage3_unit2_conv2_weight': <NDArray 256x256x3x3 @cpu(0)>,\n",
       " 'stage4_unit1_bn1_beta': <NDArray 256 @cpu(0)>,\n",
       " 'stage4_unit1_bn1_gamma': <NDArray 256 @cpu(0)>,\n",
       " 'stage4_unit1_bn1_moving_mean': <NDArray 256 @cpu(0)>,\n",
       " 'stage4_unit1_bn1_moving_var': <NDArray 256 @cpu(0)>,\n",
       " 'stage4_unit1_bn2_beta': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit1_bn2_gamma': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit1_bn2_moving_mean': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit1_bn2_moving_var': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit1_conv1_weight': <NDArray 512x256x3x3 @cpu(0)>,\n",
       " 'stage4_unit1_conv2_weight': <NDArray 512x512x3x3 @cpu(0)>,\n",
       " 'stage4_unit1_sc_weight': <NDArray 512x256x1x1 @cpu(0)>,\n",
       " 'stage4_unit2_bn1_beta': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn1_gamma': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn1_moving_mean': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn1_moving_var': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn2_beta': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn2_gamma': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn2_moving_mean': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_bn2_moving_var': <NDArray 512 @cpu(0)>,\n",
       " 'stage4_unit2_conv1_weight': <NDArray 512x512x3x3 @cpu(0)>,\n",
       " 'stage4_unit2_conv2_weight': <NDArray 512x512x3x3 @cpu(0)>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_params.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
