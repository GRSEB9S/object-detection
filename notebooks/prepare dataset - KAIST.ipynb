{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# libs\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from scipy import misc\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# useful functions \n",
    "def save_image_set_txt(path, index):\n",
    "    f = open(path, 'w')\n",
    "    for ind in index:\n",
    "        f.write(ind+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(5)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique images 7061\n"
     ]
    }
   ],
   "source": [
    "# read annotations from txt files to DataFrame\n",
    "ann_path = '../datasets/final/annotations/'\n",
    "true_bboxs = []\n",
    "\n",
    "for vid_set in sorted(os.listdir(ann_path)):\n",
    "    for vid in sorted(os.listdir(ann_path+vid_set)):\n",
    "        for i, k in enumerate(sorted(os.listdir(ann_path+vid_set+'/' + vid))):\n",
    "            filename = ann_path+vid_set+'/' +vid + '/' + k\n",
    "            # check if annotation is empy\n",
    "            if os.stat(filename).st_size > 0:\n",
    "                f = open(filename,\"r\")                \n",
    "                info = f.readlines()\n",
    "                for bbox in info:\n",
    "                    splitted = bbox.split(' ')\n",
    "                    im_id = k[:-4]\n",
    "                    cls = splitted[0]\n",
    "                    x = splitted[1]\n",
    "                    y = splitted[2]\n",
    "                    width = splitted[3]\n",
    "                    height = splitted[4]\n",
    "                    occluded = splitted[5]\n",
    "                    # KAIST reasonable configuration (not occluded, visible extent and more than 55 px)\n",
    "                    if int(height)>=55 and int(occluded)==0:\n",
    "                        true_bboxs.append([vid_set+'-'+vid+'-'+im_id, cls, x, y, width, height])\n",
    "data = pd.DataFrame(true_bboxs, columns=['INDEX', 'CLS', 'X', 'Y', 'W', 'H'])   \n",
    "data = data[data.CLS.isin(['person'])]\n",
    "\n",
    "print 'unique images', len(data.INDEX.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img:  6660\n",
      "test_img: 401\n",
      "test_day_img 274\n",
      "test_night_img 127\n"
     ]
    }
   ],
   "source": [
    "dataset = 'kaist'\n",
    "extension = '.png'\n",
    "draw_results = True\n",
    "dataset_path = '../datasets/final/images/'\n",
    "\n",
    "train_sets = ['set00', 'set01', 'set02', 'set03', 'set04', 'set05']\n",
    "test_sets  = ['set06', 'set07', 'set08', 'set09', 'set10', 'set11']\n",
    "test_day_sets = ['set06', 'set07', 'set08']\n",
    "test_night_sets = ['set09', 'set10', 'set11']\n",
    "    \n",
    "converted_dataset_folder = os.path.join(os.getcwd(), dataset)\n",
    "conv_images_path = os.path.join(converted_dataset_folder, 'images')    \n",
    "conv_annotations = os.path.join(converted_dataset_folder, 'annotations') \n",
    "conv_img_sets = os.path.join(converted_dataset_folder, 'image_sets') \n",
    "figures = os.path.join(converted_dataset_folder, 'bbox_pictures') \n",
    "\n",
    "image_set_train = os.path.join(converted_dataset_folder, 'image_sets', 'train.txt')\n",
    "image_set_val = os.path.join(converted_dataset_folder, 'image_sets', 'val.txt')\n",
    "image_set_test  = os.path.join(converted_dataset_folder, 'image_sets', 'test.txt') \n",
    "image_set_test_day  = os.path.join(converted_dataset_folder, 'image_sets', 'test_day.txt')\n",
    "image_set_test_night  = os.path.join(converted_dataset_folder, 'image_sets', 'test_night.txt')\n",
    "\n",
    "if not os.path.exists(converted_dataset_folder):\n",
    "    os.makedirs(converted_dataset_folder)\n",
    "    os.makedirs(conv_images_path)\n",
    "    os.makedirs(conv_annotations)\n",
    "    os.makedirs(conv_img_sets)\n",
    "    os.makedirs(figures)\n",
    "    \n",
    "train_index = []\n",
    "test_index = []\n",
    "test_day_index = []\n",
    "test_night_index = []\n",
    "\n",
    "for ind, INDEX in enumerate(data.INDEX.unique()):\n",
    "    # find all notes with this index\n",
    "    index_data = data[data.INDEX == INDEX]\n",
    "    vid_set, vid, IM_ID = INDEX.split('-')\n",
    "    \n",
    "    if vid_set in train_sets:\n",
    "        train_index.append(dataset+INDEX)        \n",
    "    elif vid_set in test_sets:\n",
    "        test_index.append(dataset+INDEX)\n",
    "        if vid_set in test_day_sets:\n",
    "            test_day_index.append(dataset+INDEX)\n",
    "        elif vid_set in test_night_sets:\n",
    "            test_night_index.append(dataset+INDEX)\n",
    "    \n",
    "    image = misc.imread((dataset_path + vid_set + '/' + vid +'/' + IM_ID + extension))\n",
    "    \n",
    "    if dataset == 'kaist': \n",
    "        # save image in dataset images_folder\n",
    "        np.save(conv_images_path + '/'+ dataset+INDEX + '.npy', image)\n",
    "        \n",
    "        if draw_results and ind%100==0:\n",
    "            #split data to RGB and TIR for visualization\n",
    "            rgb = image[:,:,:3].copy()\n",
    "            tir = image[:,:,3].copy()\n",
    "\n",
    "\n",
    "    # add basic annotations info     \n",
    "    f = open(conv_annotations + '/' + dataset + INDEX + '.xml','w')\n",
    "    line = \"<annotation>\" + '\\n'\n",
    "    f.write(line)\n",
    "    line = '\\t\\t<folder>' + \"folder\" + '</folder>' + '\\n'\n",
    "    f.write(line)\n",
    "    line = '\\t\\t<filename>' + dataset + INDEX + '</filename>' + '\\n'\n",
    "    f.write(line)\n",
    "    line = '\\t\\t<source>\\n\\t\\t<database>Source</database>\\n\\t</source>\\n'\n",
    "    f.write(line)\n",
    "    (width, height) = image.shape[0], image.shape[1]\n",
    "    line = '\\t<size>\\n\\t\\t<width>'+ str(width) + '</width>\\n\\t\\t<height>' + str(height) + '</height>\\n\\t'\n",
    "    line += '\\t<depth>3</depth>\\n\\t</size>'\n",
    "    f.write(line)\n",
    "    line = '\\n\\t<segmented>Unspecified</segmented>'\n",
    "    f.write(line)\n",
    "\n",
    "    # get annotations only for this picture\n",
    "    for idx, row in index_data.iterrows():    \n",
    "        x=int(row[2])\n",
    "        y=int(row[3])\n",
    "        w=int(row[4])\n",
    "        h=int(row[5])\n",
    "        line = '\\n\\t<object>'\n",
    "        line += '\\n\\t\\t<name>'+row[1]+'</name>\\n\\t\\t<pose>Unspecified</pose>'\n",
    "        line += '\\n\\t\\t<truncated>Unspecified</truncated>\\n\\t\\t<difficult>0</difficult>'\n",
    "        line += '\\n\\t\\t<bndbox>\\n\\t\\t\\t<xmin>' + str(x) + '</xmin>'            \n",
    "        line += '\\n\\t\\t\\t<ymin>' + str(y) + '</ymin>'\n",
    "        line += '\\n\\t\\t\\t<xmax>' + str(x+w) + '</xmax>'\n",
    "        line += '\\n\\t\\t\\t<ymax>' + str(y+h) + '</ymax>'\n",
    "        line += '\\n\\t\\t</bndbox>'\n",
    "        line += '\\n\\t</object>\\n' \n",
    "        f.write(line) \n",
    "\n",
    "        if draw_results and ind%100==0:\n",
    "            if dataset == 'caltech':\n",
    "                cv2.rectangle(rgb,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "            if dataset == 'kaist':\n",
    "                cv2.rectangle(rgb,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                cv2.rectangle(tir,(x,y),(x+w,y+h),(0,255,0),2) \n",
    "\n",
    "    line = \"</annotation>\" + '\\n'\n",
    "    f.write(line)\n",
    "    f.close()\n",
    "\n",
    "    if draw_results and dataset=='caltech' and ind%100==0:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(rgb)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures+ '/'+INDEX+extension)\n",
    "        plt.close()\n",
    "\n",
    "    if draw_results and dataset=='kaist' and ind%100==0:\n",
    "        # create/save figures with thermal-rgb pairs\n",
    "        fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(20, 20))\n",
    "        ax = axes.ravel()\n",
    "        ax[0].imshow(rgb)\n",
    "        ax[0].set_title('RGB')\n",
    "        ax[0].axis('off')\n",
    "        ax[1].imshow(tir, cmap=plt.get_cmap('Spectral_r'))\n",
    "        ax[1].set_title('TIR')\n",
    "        ax[1].axis('off')\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(figures+ '/'+INDEX+extension)\n",
    "        plt.close(fig)\n",
    "\n",
    "# save current image sets\n",
    "save_image_set_txt(image_set_train, train_index)\n",
    "save_image_set_txt(image_set_test, test_index) \n",
    "save_image_set_txt(image_set_test_day, test_day_index)\n",
    "save_image_set_txt(image_set_test_night, test_night_index)\n",
    "\n",
    "# print info\n",
    "print 'train_img: ', len(train_index)\n",
    "print 'test_img:', len(test_index)\n",
    "print 'test_day_img', len(test_day_index)\n",
    "print 'test_night_img', len(test_night_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:  89.909961557\n",
      "G:  83.8302041534\n",
      "B:  74.1431794542\n",
      "T:  42.6318449296\n"
     ]
    }
   ],
   "source": [
    "# calculate mean for training set\n",
    "mean_pixel_r = []\n",
    "mean_pixel_g = []\n",
    "mean_pixel_b = []\n",
    "mean_pixel_tir = []\n",
    "\n",
    "for i, name in enumerate(os.listdir('../mxnet-ssd/data/custom/images/')):\n",
    "    if name[:-4] in train_index:\n",
    "        image_rgb = np.load(('../mxnet-ssd/data/custom/images/'+name))\n",
    "        image_rgb = np.load((conv_images_path+'/'+name))\n",
    "        mean_pixel_r.append(image_rgb[:,:,0].mean())\n",
    "        mean_pixel_g.append(image_rgb[:,:,1].mean())\n",
    "        mean_pixel_b.append(image_rgb[:,:,2].mean())\n",
    "        mean_pixel_tir.append(image_rgb[:,:,3].mean())\n",
    "        \n",
    "# print pixel values\n",
    "print 'R: ', np.array(mean_pixel_r).mean()\n",
    "print 'G: ', np.array(mean_pixel_g).mean()\n",
    "print 'B: ', np.array(mean_pixel_b).mean()\n",
    "print 'T: ', np.array(mean_pixel_tir).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(os.listdir('../mxnet-ssd/data/custom/images/')):\n",
    "    image_rgbt = np.load(('../mxnet-ssd/data/custom/images/'+name))\n",
    "    misc.imsave(('../mxnet-ssd/data/custom/images_rgb/'+name[:-4]+'.jpg'), image_rgbt[:,:,:3])\n",
    "    misc.imsave(('../mxnet-ssd/data/custom/images_tir/'+name[:-4]+'.jpg'), image_rgbt[:,:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
