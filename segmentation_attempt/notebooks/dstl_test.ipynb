{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-coastal 1\n",
    "# 1-blue 2\n",
    "# 2-green 3\n",
    "# 3-yellow 4\n",
    "# 4-red 5 \n",
    "# 5-red edge 6\n",
    "# 6-near-IR1 7\n",
    "# 7-near-IR2 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from helpers import Helper\n",
    "import numpy as np\n",
    "import random\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rescale, resize\n",
    "\n",
    "def calc_jac(pred, label):\n",
    "    itersec = np.multiply(pred, label).sum()\n",
    "    summ = (pred+label).sum()\n",
    "    jac = itersec/(summ-itersec)\n",
    "    return jac\n",
    "\n",
    "def dilation(binary, kernel_type):\n",
    "    return cv2.dilate(binary , kernel_type, iterations = 5)\n",
    "\n",
    "def erosion(binary, kernel_type):\n",
    "    return cv2.erode(binary, kernel_type, iterations = 5)\n",
    "\n",
    "def ellipse_open(binary, kernel_type): \n",
    "    return cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_type)\n",
    "\n",
    "def best_morphology(binary, label):\n",
    "    \n",
    "    # delete noise\n",
    "    # noise removal\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    opening = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations = 2)\n",
    "    \n",
    "#     kernel_size = 5\n",
    "#     kernel = np.ones((kernel_size, kernel_size),np.uint8)\n",
    "#     opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # test best morphology\n",
    "    kernel_size = 3\n",
    "    kernel_type = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(kernel_size, kernel_size)) \n",
    "    \n",
    "    jac_d = calc_jac(opening, label)\n",
    "    jac_e = calc_jac(erosion(opening, kernel_type), label)\n",
    "    jac_ellipse_open = calc_jac(ellipse_open(opening, kernel_type), label)\n",
    "    \n",
    "    morph = [dilation, erosion, ellipse_open]\n",
    "    ind = np.argmax([jac_d, jac_e, jac_ellipse_open])\n",
    "    return morph[ind], kernel_type\n",
    "\n",
    "def normalize(bands):\n",
    "    out = np.zeros_like(bands).astype(np.float32)\n",
    "    n = bands.shape[2]\n",
    "    print bands.shape\n",
    "    for i in range(n):\n",
    "        out[:, :, i] = equalize_adapthist((bands[:,:,i]).astype(np.float32))\n",
    "\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "def stretch_n(bands, lower_percent=0, higher_percent=100):\n",
    "    out = np.zeros_like(bands).astype(np.float32)\n",
    "    n = bands.shape[2]\n",
    "\n",
    "    for i in range(n):\n",
    "        a = 0  # np.min(band)\n",
    "        b = 1  # np.max(band)\n",
    "        c = np.percentile(bands[:, :, i], lower_percent)\n",
    "        d = np.percentile(bands[:, :, i], higher_percent)\n",
    "        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n",
    "        t[t < a] = a\n",
    "        t[t > b] = b\n",
    "        out[:, :, i] = t\n",
    "\n",
    "    return out.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/train_wkt_v4.csv')\n",
    "data = data[data.MultipolygonWKT != 'MULTIPOLYGON EMPTY']\n",
    "grid_sizes_fname = '../input/grid_sizes.csv'\n",
    "wkt_fname = '../input/train_wkt_v4.csv'\n",
    "image_fname = '../input/three_band/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "helper = Helper()\n",
    "pr_size = 512\n",
    "\n",
    "for IM_ID in data[data.ClassType == 10].ImageId.values:\n",
    "    print IM_ID\n",
    "    \n",
    "    rgb, mask = helper.load_im_polymask(IM_ID, '10', image_fname, wkt_fname, grid_sizes_fname)\n",
    "    m = tiff.imread('../input/M/train/{}.tif'.format(IM_ID))\n",
    "    \n",
    "    NIR=resize(m[6,:,:], (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis] \n",
    "    NIR2=resize(m[7,:,:], (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    B=resize(m[1,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    G=resize(m[2,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    R=resize(m[4,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    C=resize(m[0,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    Y=resize(m[3,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    RE=resize(m[5,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    \n",
    "    bands = np.concatenate([C, B, G, Y,R, RE, NIR, NIR2], axis=2)\n",
    "    rgb = bands\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(0,6):    \n",
    "        for j in range(0,6):\n",
    "            crop = rgb[i*pr_size:i*pr_size+pr_size, j*pr_size:j*pr_size+pr_size, :]\n",
    "            msk = mask[i*pr_size:i*pr_size+pr_size, j*pr_size:j*pr_size+pr_size]\n",
    "            \n",
    "            tiff.imsave('data/train/A/{}.tif'.format(IM_ID+str(i)+str(j)), crop)\n",
    "            tiff.imsave('data/train/B/{}.tif'.format(IM_ID+str(i)+str(j)), msk)\n",
    "            counter+=1\n",
    "            \n",
    "        crop = rgb[i*pr_size:i*pr_size+pr_size, -pr_size:, :]\n",
    "        msk = mask[i*pr_size:i*pr_size+pr_size, -pr_size:]\n",
    "        \n",
    "        tiff.imsave('data/train/A/{}.tif'.format(IM_ID+str(i)+str(j)+'right'), crop)\n",
    "        tiff.imsave('data/train/B/{}.tif'.format(IM_ID+str(i)+str(j)+'right'), msk)\n",
    "        counter+=1\n",
    "        \n",
    "        # predictions for bottom part \n",
    "        if i==5:\n",
    "            for j in range(0,6):\n",
    "                crop = rgb[-pr_size:, j*pr_size:j*pr_size+pr_size, :]\n",
    "                msk= mask[-pr_size:, j*pr_size:j*pr_size+pr_size]\n",
    "                \n",
    "                tiff.imsave('data/train/A/{}.tif'.format(IM_ID+str(i+1)+str(j)), crop)\n",
    "                tiff.imsave('data/train/B/{}.tif'.format(IM_ID+str(i+1)+str(j)), msk)\n",
    "                counter+=1\n",
    "                \n",
    "            crop = rgb[-pr_size:, -pr_size:, :]\n",
    "            msk = mask[-pr_size:, -pr_size:]\n",
    "            \n",
    "            tiff.imsave('data/train/A/{}.tif'.format(IM_ID+str(i+1)+str(j+1)), crop)\n",
    "            tiff.imsave('data/train/B/{}.tif'.format(IM_ID+str(i+1)+str(j+1)), msk)\n",
    "            counter+=1\n",
    "    print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper = Helper()\n",
    "for IM_ID in data[data.ClassType == 9].ImageId.values:\n",
    "    rgb, mask = helper.load_im_polymask(IM_ID, '9', image_fname, wkt_fname, grid_sizes_fname)\n",
    "    plt.imshow(stretch_n(rgb, lower_percent=2, higher_percent=98))\n",
    "    plt.show()\n",
    "    plt.imshow(mask)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean and std\n",
    "mean = np.empty((637, 512, 512, 8))\n",
    "for i, IM_ID in enumerate(os.listdir('data/train/A/')):\n",
    "    img = tiff.imread('data/train/A/{}.tif'.format(IM_ID[:-4]))\n",
    "    mean[i, :,:, :] = img\n",
    "print mean.shape\n",
    "mean_img = np.mean(mean, axis=0)\n",
    "tiff.imsave('data/mean_img.tif', mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_img = np.std(mean, axis=0)\n",
    "tiff.imsave('data/std_img.tif', std_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "helper = Helper()\n",
    "pr_size = 512\n",
    "\n",
    "for IM_ID in data[data.ClassType == 10].ImageId.values[-1:]:\n",
    "    print IM_ID\n",
    "    rgb, mask = helper.load_im_polymask(IM_ID, '10', image_fname, wkt_fname, grid_sizes_fname)\n",
    "    m = tiff.imread('../input/M/train/{}.tif'.format(IM_ID))\n",
    "    NIR = resize(m[6,:,:], (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis] \n",
    "    NIR2 = resize(m[7,:,:], (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    B = resize(m[1,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    G = resize(m[2,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    R = resize(m[4,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    C = resize(m[0,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    Y = resize(m[3,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    RE = resize(m[5,:,:],   (rgb.shape[0], rgb.shape[1]))[:,:, np.newaxis]\n",
    "    \n",
    "    bands = np.concatenate([C, B, G, Y,R, RE, NIR, NIR2], axis=2)\n",
    "    rgb=bands\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(0,6):    \n",
    "        for j in range(0,6):\n",
    "            crop = rgb[i*pr_size:i*pr_size+pr_size, j*pr_size:j*pr_size+pr_size, :]\n",
    "            msk = mask[i*pr_size:i*pr_size+pr_size, j*pr_size:j*pr_size+pr_size]\n",
    "            \n",
    "            tiff.imsave('data/val/A/{}.tif'.format(IM_ID+str(i)+str(j)), crop)\n",
    "            tiff.imsave('data/val/B/{}.tif'.format(IM_ID+str(i)+str(j)), msk)\n",
    "            counter+=1\n",
    "            \n",
    "        crop = rgb[i*pr_size:i*pr_size+pr_size, -pr_size:, :]\n",
    "        msk = mask[i*pr_size:i*pr_size+pr_size, -pr_size:]\n",
    "        \n",
    "        tiff.imsave('data/val/A/{}.tif'.format(IM_ID+str(i)+str(j)+'right'), crop)\n",
    "        tiff.imsave('data/val/B/{}.tif'.format(IM_ID+str(i)+str(j)+'right'), msk)\n",
    "        counter+=1\n",
    "        \n",
    "        # predictions for bottom part \n",
    "        if i==5:\n",
    "            for j in range(0,6):\n",
    "                crop = rgb[-pr_size:, j*pr_size:j*pr_size+pr_size, :]\n",
    "                msk= mask[-pr_size:, j*pr_size:j*pr_size+pr_size]\n",
    "                \n",
    "                tiff.imsave('data/val/A/{}.tif'.format(IM_ID+str(i+1)+str(j)), crop)\n",
    "                tiff.imsave('data/val/B/{}.tif'.format(IM_ID+str(i+1)+str(j)), msk)\n",
    "                counter+=1\n",
    "                \n",
    "            crop = rgb[-pr_size:, -pr_size:, :]\n",
    "            msk = mask[-pr_size:, -pr_size:]\n",
    "            \n",
    "            tiff.imsave('data/val/A/{}.tif'.format(IM_ID+str(i+1)+str(j+1)), crop)\n",
    "            tiff.imsave('data/val/B/{}.tif'.format(IM_ID+str(i+1)+str(j+1)), msk)\n",
    "            counter+=1\n",
    "    print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sw = pd.read_csv('../submits/0.3137_standing_water_index.csv')\n",
    "#road = pd.read_csv('../submits/road_p2p_final_no_water.csv')\n",
    "# build = pd.read_csv('../submits/build_p2p_final.csv')\n",
    "\n",
    "crops = pd.read_csv('../submits/0.6929_crops_pix2pix.csv')\n",
    "man_made = pd.read_csv('../submits/manmade_final.csv')\n",
    "waterway = pd.read_csv('../submits/0.9528_waterway_index.csv')\n",
    "trees = pd.read_csv('../submits/0.4722_trees_pix2pix.csv')\n",
    "tracks = pd.read_csv('../submits/tracks_p2p_final.csv')\n",
    "vl = pd.read_csv('../submits/vl_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main submit\n",
    "df = pd.read_csv('../submits/1_with_water.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 1 \n",
    "for idx, row in df.iterrows():\n",
    "    _id = row[0]\n",
    "    kls = row[1]\n",
    "    \n",
    "#     if kls == 1:\n",
    "#         df.iloc[idx, 2] = build[(build.ClassType==kls) & (build.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "   \n",
    "    if kls == 2:\n",
    "        df.iloc[idx, 2] = man_made[(man_made.ClassType==kls) & (man_made.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "    \n",
    "#     if kls == 3:\n",
    "#         df.iloc[idx, 2] = road[(road.ClassType==kls) & (road.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "    \n",
    "    if kls == 4:\n",
    "        df.iloc[idx, 2] = tracks[(tracks.ClassType==kls) & (tracks.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "    \n",
    "    if kls == 5:\n",
    "        df.iloc[idx, 2] = trees[(trees.ClassType==kls) & (trees.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "    \n",
    "#     if kls == 6:\n",
    "#         df.iloc[idx, 2] = crops[(crops.ClassType==kls) & (crops.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "    \n",
    "    if kls == 7:\n",
    "        df.iloc[idx, 2] = waterway[(waterway.ClassType==kls) & (waterway.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "    \n",
    "#     if kls == 8:\n",
    "#         df.iloc[idx, 2] = sw[(sw.ClassType==kls) & (sw.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "\n",
    "    if kls == 9:\n",
    "        df.iloc[idx, 2] = vl[(vl.ClassType==kls) & (vl.ImageId==_id)].MultipolygonWKT.values[0]\n",
    "        \n",
    "    print counter\n",
    "    counter += 1\n",
    "\n",
    "print df.head()\n",
    "df.to_csv('final_submit_adversarial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv('final_submit_adversarial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "6100_0_2 6060_1_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final[(final.ImageId == '6060_1_4') & (final.ClassType == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.iloc[1911, 2] = 'MULTIPOLYGON EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.to_csv('final_submit_adversarial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
